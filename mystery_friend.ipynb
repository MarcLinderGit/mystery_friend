{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mystery Friend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've received an anonymous postcard from a friend who you haven't seen in years. Your friend did not leave a name, but the card is definitely addressed to you. So far, you've narrowed your search down to three friends, based on handwriting:\n",
    "- Emma Goldman\n",
    "- Matthew Henson\n",
    "- TingFang Wu\n",
    "\n",
    "But which one sent you the card?\n",
    "\n",
    "Just like you can classify a message as spam or not spam with a spam filter, you can classify writing as related to one friend or another by building a kind of friend writing classifier. You have past writing from all three friends stored up in the variable `friends_docs`, which means you can use scikit-learn's bag-of-words and Naive Bayes classifier to determine who the mystery friend is!\n",
    "\n",
    "Ready?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Vectors Are in the Bag with Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62461b1",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "# Import messages to process\n",
    "import import_ipynb\n",
    "from messages.goldman_emma_raw import goldman_docs\n",
    "from messages.henson_matthew_raw import henson_docs\n",
    "from messages.wu_tingfang_raw import wu_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab16c75",
   "metadata": {},
   "source": [
    "## Text Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "62a1640c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's an excerpt from Emma Goldman's message:\n",
      "  What he gives to the world is only gray and hideous\n",
      "things, reflecting a dull and hideous existence,--too weak to live,\n",
      "too cowardly to die \n",
      "\n",
      "Here's an excerpt from Matthew Henson's message:\n",
      " Miss Marie Ahnighito Peary, aged about ten months, who\n",
      "first saw the light of day at Anniversary Lodge on the 12th of the\n",
      "previous September, was taken by her mother to her kinfolks in the\n",
      "South \n",
      "\n",
      "Here's an excerpt from TingFang Wu's message:\n",
      "  Let us, for instance, compare England with the United\n",
      "States \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect lines from the messages of each friend\n",
    "print(\"Here's an excerpt from Emma Goldman's message:\\n\", goldman_docs[49], \"\\n\")\n",
    "print(\"Here's an excerpt from Matthew Henson's message:\\n\", henson_docs[49], \"\\n\")\n",
    "print(\"Here's an excerpt from TingFang Wu's message:\\n\", wu_docs[49], \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d26cd0",
   "metadata": {},
   "source": [
    "## Feature Extraction (Vectorization) using Bag-of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bow_vectorizer:\n",
    "bow_vectorizer = CountVectorizer()\n",
    "\n",
    "# Combine messages to one document\n",
    "friends_docs = goldman_docs + henson_docs + wu_docs\n",
    "\n",
    "# Define friends_vectors:\n",
    "friends_vectors = bow_vectorizer.fit_transform(friends_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new mystey message we want to classify\n",
    "mystery_message = \"\"\"\n",
    "My friend,\n",
    "From the 10th of July to the 13th, a fierce storm raged, clouds of\n",
    "freeing spray broke over the ship, incasing her in a coat of icy mail,\n",
    "and the tempest forced all of the ice out of the lower end of the\n",
    "channel and beyond as far as the eye could see, but the _Roosevelt_\n",
    "still remained surrounded by ice.\n",
    "Hope to see you soon.\n",
    "\"\"\"\n",
    "\n",
    "# Define mystery_vector:\n",
    "mystery_vector = bow_vectorizer.transform([mystery_message])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Mystery Friend Gets Classified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. You've vectorized and prepared all the documents. Let's take a look at your friends' writing samples to get a sense of how they write.\n",
    "\n",
    "   Print out one document of each friend's writing - try any one between `0` and `140`. (Your friends' documents are stored in `goldman_docs`, `henson_docs`, and `wu_docs`.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ec6def",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The postcard was from Emma!\n"
     ]
    }
   ],
   "source": [
    "# Define friends_classifier\n",
    "friends_classifier = MultinomialNB()\n",
    "\n",
    "# Define friends_labels, length of documents indicates number of words\n",
    "friends_labels = [\"Emma\"] * len(goldman_docs) + [\"Matthew\"] * len(henson_docs) + [\"Tingfang\"] * len(wu_docs)\n",
    "\n",
    "# Train the classifier\n",
    "friends_classifier.fit(friends_vectors, friends_labels)\n",
    "\n",
    "# Predict mystery_vector\n",
    "predictions = friends_classifier.predict(mystery_vector)\n",
    "mystery_friend = predictions[0] if predictions[0] else \"someone else\"\n",
    "print(\"The postcard was from {}!\".format(mystery_friend))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d520da",
   "metadata": {},
   "source": [
    "Taking a random excerpt from Emma Goldman's \"The place of the individual in society\" (source: [https://www.gutenberg.org/cache/epub/71418/pg71418.txt]) allows us to test how the classifier holds up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystery_message = \"\"\"\n",
    "The interests of the State and those of the individual differ\n",
    "fundamentally and are antagonistic. The State and the political and\n",
    "economic institutions it supports can exist only by fashioning the\n",
    "individual to their particular purpose; training him to respect “law and\n",
    "order;” teaching him obedience, submission and unquestioning faith in\n",
    "the wisdom and justice of government; above all, loyal service and\n",
    "complete self-sacrifice when the State commands it, as in war. The State\n",
    "puts itself and its interests even above the claims of religion and of\n",
    "God. It punishes religious or conscientious scruples against\n",
    "individuality because there is no individuality without liberty, and\n",
    "liberty is the greatest menace to authority.\n",
    "\"\"\"\n",
    "\n",
    "# Define mystery_vector:\n",
    "mystery_vector = bow_vectorizer.transform([mystery_message])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3db45fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The likelihood of the mystery message being from Emma Goldman is 1.10%\n",
      "The likelihood of the mystery message being from Matthew Henson is 98.90%\n",
      "The likelihood of the mystery message being from TingFang Wu is 0.00%\n",
      "\n",
      "Conclusion:\n",
      "Based on these probabilities, the mystery message is most likely from Matthew Henson.\n"
     ]
    }
   ],
   "source": [
    "# Predict mystery_vector\n",
    "probabilities = friends_classifier.predict_proba(mystery_vector)\n",
    "\n",
    "# Create list of authors\n",
    "author_names = [\"Emma Goldman\", \"Matthew Henson\", \"TingFang Wu\"]\n",
    "\n",
    "# Extract probabilities for each author\n",
    "author_probabilities = probabilities[0]\n",
    "\n",
    "# Initialize a dictionary to store the likelihood for each author\n",
    "likelihoods = {}\n",
    "\n",
    "for i, author in enumerate(author_names):\n",
    "    likelihoods[author] = author_probabilities[i]\n",
    "\n",
    "# Output the likelihood for each author\n",
    "for author, likelihood in likelihoods.items():\n",
    "    print(f\"The likelihood of the mystery message being from {author} is {likelihood:.2%}\")\n",
    "\n",
    "\n",
    "# Find the index with the highest probability\n",
    "index_max_probability = np.argmax(author_probabilities)\n",
    "\n",
    "# Output the result\n",
    "print(\"\")\n",
    "print(\"Conclusion:\")\n",
    "print(f\"Based on these probabilities, the mystery message is most likely from {author_names[index_max_probability]}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
